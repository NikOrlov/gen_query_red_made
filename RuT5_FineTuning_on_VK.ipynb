{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da59680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 00:18:55.988914: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 00:18:56.569475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "import sentencepiece\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import os\n",
    "from rank_bm25 import BM25Okapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee31835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = 'test_dev/test_dev_'\n",
    "\n",
    "vk_qrels = pd.read_csv(vk + 'qrels.tsv', names=['id', 'query_id', 'doc_id'],  sep='\\t')\n",
    "vk_docs = pd.read_csv(vk + 'docs.tsv', names=['id', 'doc_id', 'data'],  sep='\\t')\n",
    "vk_queries = pd.read_csv(vk + 'queries.tsv', names=['id', 'query_id', 'data'],  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eaa7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joined_file(df_docs, df_qrels, df_queries, path_processed_joined=None):\n",
    "    joined_df = df_qrels.merge(df_queries, on='query_id').merge(df_docs, on='doc_id', how='left')[['query_id', 'data_x', 'doc_id', 'data_y']]\n",
    "    joined_df.rename(columns={'data_x':'query_data', 'data_y':'doc_data'}, inplace=True)\n",
    "    if path_processed_joined:\n",
    "        joined_df.to_csv(path_processed_joined, sep='\\t', index=None, header=None)\n",
    "    return joined_df\n",
    "\n",
    "def preprocess_function(dataset):\n",
    "    docs = [str(i) for i in dataset['doc_data'].values]\n",
    "    lbls = [str(i) for i in dataset['query_data'].values]\n",
    "    inputs = tokenizer(docs, max_length=max_input_length, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(lbls, max_length=max_target_input, truncation=True)\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels!= - 100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_labels]\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: v * 100 for k, v in result.items()}\n",
    "    \n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result['gen_len'] = np.mean(prediction_lens)\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "vk_joined = create_joined_file(vk_docs, vk_qrels, vk_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95db0906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15857, 15857)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vk_qrels), len(vk_docs) #, len(ms_qrels), len(ms_docs), len(vk_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f211d4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_data</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 00 дом muzono net raim feat artur adil скачать</td>\n",
       "      <td>D8</td>\n",
       "      <td>показать меню главная узбекские песни зарубежн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0 16 0 8t t</td>\n",
       "      <td>D15</td>\n",
       "      <td>войти на сайт главная задать вопрос представьт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0 5 текила максимо де кодорниз сильвер 38</td>\n",
       "      <td>D28</td>\n",
       "      <td>280 другие спиртные напитки с содержанием этил...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                        query_data doc_id  \\\n",
       "0         0  0 00 дом muzono net raim feat artur adil скачать     D8   \n",
       "1         1                                       0 16 0 8t t    D15   \n",
       "2         2         0 5 текила максимо де кодорниз сильвер 38    D28   \n",
       "\n",
       "                                            doc_data  \n",
       "0  показать меню главная узбекские песни зарубежн...  \n",
       "1  войти на сайт главная задать вопрос представьт...  \n",
       "2  280 другие спиртные напитки с содержанием этил...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vk_joined[['query_id', 'query_data', 'doc_id', 'doc_data']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd210ee1",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abab4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '/home/tatiana/MADE/Project/VK_Dataset/rut5-base-absum-finetuned-rut513000_3_epochs/checkpoint-31500'\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "dataset = vk_joined[['doc_data', 'query_data']]\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset[:train_size].reset_index(drop=True)\n",
    "test_dataset = dataset[train_size:].reset_index(drop=True)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item['input_ids'] = self.encodings[idx]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f82511",
   "metadata": {},
   "source": [
    "### Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e90b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0dc457",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32634bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12685, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbee7e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3606: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "max_input_length = 400\n",
    "max_target_input = 100\n",
    "\n",
    "tokenized_train_dataset = preprocess_function(train_dataset)\n",
    "tokenized_test_dataset = preprocess_function(test_dataset)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "training_set = Dataset(tokenized_train_dataset['input_ids'], tokenized_train_dataset['labels'])\n",
    "validation_set = Dataset(tokenized_test_dataset['input_ids'], tokenized_test_dataset['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6699fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "model_name = MODEL_NAME.split('/')[-1]\n",
    "\n",
    "EXPERIMENT = '31500_5_epochs'\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f'{model_name}-finetuned-rut5' + EXPERIMENT,\n",
    "    evaluation_strategy='epoch', \n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1, \n",
    "    num_train_epochs=5, \n",
    "    predict_with_generate=True, \n",
    "    fp16=False,\n",
    "    push_to_hub=False    \n",
    ")\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3097b36",
   "metadata": {},
   "source": [
    "### Дообучение модели в течение 5 эпох  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1210588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tatiana/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/tatiana/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31715' max='31715' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31715/31715 2:23:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.094200</td>\n",
       "      <td>2.777075</td>\n",
       "      <td>7.893500</td>\n",
       "      <td>1.752000</td>\n",
       "      <td>7.856800</td>\n",
       "      <td>7.828500</td>\n",
       "      <td>10.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.946800</td>\n",
       "      <td>2.732403</td>\n",
       "      <td>8.335900</td>\n",
       "      <td>1.883300</td>\n",
       "      <td>8.295000</td>\n",
       "      <td>8.258200</td>\n",
       "      <td>10.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.809100</td>\n",
       "      <td>2.718696</td>\n",
       "      <td>8.178800</td>\n",
       "      <td>1.691400</td>\n",
       "      <td>8.158100</td>\n",
       "      <td>8.136400</td>\n",
       "      <td>10.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>2.716847</td>\n",
       "      <td>8.737500</td>\n",
       "      <td>1.881300</td>\n",
       "      <td>8.692500</td>\n",
       "      <td>8.673200</td>\n",
       "      <td>11.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.651600</td>\n",
       "      <td>2.718578</td>\n",
       "      <td>8.582100</td>\n",
       "      <td>1.784900</td>\n",
       "      <td>8.572000</td>\n",
       "      <td>8.565000</td>\n",
       "      <td>10.882400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=31715, training_loss=2.895531035304051, metrics={'train_runtime': 8635.8651, 'train_samples_per_second': 7.344, 'train_steps_per_second': 3.672, 'total_flos': 3.352394575291392e+16, 'train_loss': 2.895531035304051, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df145057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = trainer.predict(test_dataset=validation_set)\n",
    "prediction.predictions.shape\n",
    "\n",
    "preds, labels = prediction.predictions, prediction.label_ids\n",
    "decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "labels = np.where(labels!= - 100, labels, tokenizer.pad_token_id)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "decoded_labels = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd797399",
   "metadata": {},
   "source": [
    "### Предсказание дообученной и сохраненной моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eacd2f",
   "metadata": {},
   "source": [
    "## Prediction ON DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1621f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, T5Tokenizer, Seq2SeqTrainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('rut5-base-absum-finetuned-rut513000_3_epochs/checkpoint-31500')\n",
    "tokenizer = T5Tokenizer.from_pretrained('rut5-base-absum-finetuned-rut513000_3_epochs/checkpoint-31500')\n",
    "batch_size = 1\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    'rut5-base-absum-finetuned-rut5-100k_docs_2',\n",
    "    evaluation_strategy='epoch', \n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1, \n",
    "    num_train_epochs=1, \n",
    "    predict_with_generate=True, \n",
    "    fp16=False,\n",
    "    push_to_hub=False    \n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a3fcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 400\n",
    "max_target_input = 400\n",
    "\n",
    "dev_qrels = pd.read_csv('dev_docs/' + 'qrels.tsv', names=['id', 'query_id', 'doc_id'],  sep='\\t')\n",
    "dev_docs = pd.read_csv('dev_docs/' + 'docs.tsv', names=['id', 'doc_id', 'data'],  sep='\\t')\n",
    "dev_queries = pd.read_csv('dev_docs/' + 'queries.tsv', names=['id', 'query_id', 'data'],  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f90fa4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3606: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_df = create_joined_file(dev_docs, dev_qrels, dev_queries)\n",
    "pred_dataset = joined_df[['doc_data', 'query_data']]\n",
    "pred_tokenized = preprocess_function(pred_dataset)\n",
    "\n",
    "prediction_set = Dataset(pred_tokenized['input_ids'], pred_tokenized['labels'])\n",
    "prediction = trainer.predict(test_dataset=prediction_set)\n",
    "\n",
    "preds, labels = prediction.predictions, prediction.label_ids\n",
    "decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "labels = np.where(labels!= - 100, labels, tokenizer.pad_token_id)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "decoded_labels = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f56a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['preds'] = decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1edfb024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_data</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_data</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 05 diamonds rihanna скачать</td>\n",
       "      <td>D10</td>\n",
       "      <td>музофил rihanna diamonds diamonds исполнитель ...</td>\n",
       "      <td>скачать песню риганна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1 13 2 шейдеры</td>\n",
       "      <td>D487</td>\n",
       "      <td>﻿ текущая версия minecraft 116 шейдеры для min...</td>\n",
       "      <td>скачать шейдер для майнкрафт 1 6 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1 детская поликлиника в спб</td>\n",
       "      <td>D818</td>\n",
       "      <td>с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓрєрір° рё рњрћ рўр...</td>\n",
       "      <td>рё рё рё рё рё рё</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>1 й драгунский полк</td>\n",
       "      <td>D944</td>\n",
       "      <td>﻿ загрузка скачать московский 1й лейбдрагунски...</td>\n",
       "      <td>московский 1й лейб драгунский полк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>1 канал в эфире</td>\n",
       "      <td>D990</td>\n",
       "      <td>онлайн телевидение смотри самые популярные кан...</td>\n",
       "      <td>смотреть первый канал онлайн бесплатно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46</td>\n",
       "      <td>1 комнатная квартира в шилово</td>\n",
       "      <td>D1072</td>\n",
       "      <td>﻿ п шилово рязанская область специалисты вход ...</td>\n",
       "      <td>купить квартиру в рязани в аренду в москве в м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>1 псч фгку 21 отряд фпс по хабаровскому краю</td>\n",
       "      <td>D1315</td>\n",
       "      <td>вход rusen русский english фгку 21 отряд фпс п...</td>\n",
       "      <td>фпс хабаровск</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86</td>\n",
       "      <td>1001 мелоч нижний новгород</td>\n",
       "      <td>D2124</td>\n",
       "      <td>перейти к содержимому 1001 мелочь магазин хозя...</td>\n",
       "      <td>купить мягкие и мягкие мягкие мягкие и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91</td>\n",
       "      <td>103 расписание смоленск</td>\n",
       "      <td>D2201</td>\n",
       "      <td>расписание автобуса смоленск – плембаза распис...</td>\n",
       "      <td>расписание автобусов смоленск плембаза</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92</td>\n",
       "      <td>105 закон калининградской области земельные уч...</td>\n",
       "      <td>D2238</td>\n",
       "      <td>закон калининградской области об особенностях ...</td>\n",
       "      <td>закон об особенностях регулирования земельных ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                         query_data doc_id  \\\n",
       "0         0                      0 05 diamonds rihanna скачать    D10   \n",
       "1        23                                     1 13 2 шейдеры   D487   \n",
       "2        37                        1 детская поликлиника в спб   D818   \n",
       "3        41                                1 й драгунский полк   D944   \n",
       "4        43                                    1 канал в эфире   D990   \n",
       "5        46                      1 комнатная квартира в шилово  D1072   \n",
       "6        55       1 псч фгку 21 отряд фпс по хабаровскому краю  D1315   \n",
       "7        86                         1001 мелоч нижний новгород  D2124   \n",
       "8        91                            103 расписание смоленск  D2201   \n",
       "9        92  105 закон калининградской области земельные уч...  D2238   \n",
       "\n",
       "                                            doc_data  \\\n",
       "0  музофил rihanna diamonds diamonds исполнитель ...   \n",
       "1  ﻿ текущая версия minecraft 116 шейдеры для min...   \n",
       "2  с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓрєрір° рё рњрћ рўр...   \n",
       "3  ﻿ загрузка скачать московский 1й лейбдрагунски...   \n",
       "4  онлайн телевидение смотри самые популярные кан...   \n",
       "5  ﻿ п шилово рязанская область специалисты вход ...   \n",
       "6  вход rusen русский english фгку 21 отряд фпс п...   \n",
       "7  перейти к содержимому 1001 мелочь магазин хозя...   \n",
       "8  расписание автобуса смоленск – плембаза распис...   \n",
       "9  закон калининградской области об особенностях ...   \n",
       "\n",
       "                                               preds  \n",
       "0                              скачать песню риганна  \n",
       "1                 скачать шейдер для майнкрафт 1 6 2  \n",
       "2                                  рё рё рё рё рё рё  \n",
       "3                 московский 1й лейб драгунский полк  \n",
       "4             смотреть первый канал онлайн бесплатно  \n",
       "5  купить квартиру в рязани в аренду в москве в м...  \n",
       "6                                      фпс хабаровск  \n",
       "7             купить мягкие и мягкие мягкие мягкие и  \n",
       "8             расписание автобусов смоленск плембаза  \n",
       "9  закон об особенностях регулирования земельных ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4935d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_data</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_data</th>\n",
       "      <th>preds</th>\n",
       "      <th>old_doc_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 05 diamonds rihanna скачать</td>\n",
       "      <td>D10</td>\n",
       "      <td>скачать песню риганна музофил rihanna diamonds...</td>\n",
       "      <td>скачать песню риганна</td>\n",
       "      <td>музофил rihanna diamonds diamonds исполнитель ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1 13 2 шейдеры</td>\n",
       "      <td>D487</td>\n",
       "      <td>скачать шейдер для майнкрафт 1 6 2 ﻿ текущая в...</td>\n",
       "      <td>скачать шейдер для майнкрафт 1 6 2</td>\n",
       "      <td>﻿ текущая версия minecraft 116 шейдеры для min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1 детская поликлиника в спб</td>\n",
       "      <td>D818</td>\n",
       "      <td>рё рё рё рё рё рё с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓ...</td>\n",
       "      <td>рё рё рё рё рё рё</td>\n",
       "      <td>с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓрєрір° рё рњрћ рўр...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                     query_data doc_id  \\\n",
       "0         0  0 05 diamonds rihanna скачать    D10   \n",
       "1        23                 1 13 2 шейдеры   D487   \n",
       "2        37    1 детская поликлиника в спб   D818   \n",
       "\n",
       "                                            doc_data  \\\n",
       "0  скачать песню риганна музофил rihanna diamonds...   \n",
       "1  скачать шейдер для майнкрафт 1 6 2 ﻿ текущая в...   \n",
       "2  рё рё рё рё рё рё с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓ...   \n",
       "\n",
       "                                preds  \\\n",
       "0               скачать песню риганна   \n",
       "1  скачать шейдер для майнкрафт 1 6 2   \n",
       "2                   рё рё рё рё рё рё   \n",
       "\n",
       "                                        old_doc_data  \n",
       "0  музофил rihanna diamonds diamonds исполнитель ...  \n",
       "1  ﻿ текущая версия minecraft 116 шейдеры для min...  \n",
       "2  с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓрєрір° рё рњрћ рўр...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['old_doc_data'] = joined_df['doc_data']\n",
    "joined_df['doc_data'] = joined_df['preds'] + ' ' + joined_df['doc_data']\n",
    "joined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01bc84",
   "metadata": {},
   "source": [
    "### Посчитаем скор на документах + сгенерированных дообученной моделью запросах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffa43a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_data</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_data</th>\n",
       "      <th>preds</th>\n",
       "      <th>old_doc_data</th>\n",
       "      <th>predict_100</th>\n",
       "      <th>predict_100_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 05 diamonds rihanna скачать</td>\n",
       "      <td>D10</td>\n",
       "      <td>скачать песню риганна музофил rihanna diamonds...</td>\n",
       "      <td>скачать песню риганна</td>\n",
       "      <td>музофил rihanna diamonds diamonds исполнитель ...</td>\n",
       "      <td>[D10, D2394, D9849, D16322, D18018, D18794, D2...</td>\n",
       "      <td>[38.3, 5.9, 5.2, 10.9, 5.2, 8.1, 5.7, 5.4, 5.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1 13 2 шейдеры</td>\n",
       "      <td>D487</td>\n",
       "      <td>скачать шейдер для майнкрафт 1 6 2 ﻿ текущая в...</td>\n",
       "      <td>скачать шейдер для майнкрафт 1 6 2</td>\n",
       "      <td>﻿ текущая версия minecraft 116 шейдеры для min...</td>\n",
       "      <td>[D487, D7056, D18377, D20912, D45962, D47103, ...</td>\n",
       "      <td>[20.9, 11.4, 10.6, 10.8, 10.3, 10.5, 10.5, 10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1 детская поликлиника в спб</td>\n",
       "      <td>D818</td>\n",
       "      <td>рё рё рё рё рё рё с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓ...</td>\n",
       "      <td>рё рё рё рё рё рё</td>\n",
       "      <td>с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓрєрір° рё рњрћ рўр...</td>\n",
       "      <td>[D9984, D49696, D56674, D79257, D85773, D88617...</td>\n",
       "      <td>[15.4, 13.7, 13.2, 22.9, 16.1, 13.1, 14.9, 14....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                     query_data doc_id  \\\n",
       "0         0  0 05 diamonds rihanna скачать    D10   \n",
       "1        23                 1 13 2 шейдеры   D487   \n",
       "2        37    1 детская поликлиника в спб   D818   \n",
       "\n",
       "                                            doc_data  \\\n",
       "0  скачать песню риганна музофил rihanna diamonds...   \n",
       "1  скачать шейдер для майнкрафт 1 6 2 ﻿ текущая в...   \n",
       "2  рё рё рё рё рё рё с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓ...   \n",
       "\n",
       "                                preds  \\\n",
       "0               скачать песню риганна   \n",
       "1  скачать шейдер для майнкрафт 1 6 2   \n",
       "2                   рё рё рё рё рё рё   \n",
       "\n",
       "                                        old_doc_data  \\\n",
       "0  музофил rihanna diamonds diamonds исполнитель ...   \n",
       "1  ﻿ текущая версия minecraft 116 шейдеры для min...   \n",
       "2  с‡рёс‚р°р№с‚рµ рѕр°сѓ рњрѕсѓрєрір° рё рњрћ рўр...   \n",
       "\n",
       "                                         predict_100  \\\n",
       "0  [D10, D2394, D9849, D16322, D18018, D18794, D2...   \n",
       "1  [D487, D7056, D18377, D20912, D45962, D47103, ...   \n",
       "2  [D9984, D49696, D56674, D79257, D85773, D88617...   \n",
       "\n",
       "                                   predict_100_score  \n",
       "0  [38.3, 5.9, 5.2, 10.9, 5.2, 8.1, 5.7, 5.4, 5.5...  \n",
       "1  [20.9, 11.4, 10.6, 10.8, 10.3, 10.5, 10.5, 10....  \n",
       "2  [15.4, 13.7, 13.2, 22.9, 16.1, 13.1, 14.9, 14....  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from rank_bm25 import BM25Okapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = list(joined_df['doc_data'].values)\n",
    "tokenized_corpus = [str(corp).split(\" \") for corp in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def predicting_100_top_doc_id(joined_df, bm25):\n",
    "    predict_on_query = []\n",
    "    predicted_scores = []\n",
    "    for query_id, query in zip(list(joined_df['query_id']), list(joined_df['query_data'])):\n",
    "        query = query.split()\n",
    "        score = bm25.get_scores(query)\n",
    "        top_100_scores = np.round(score[score >= pd.Series(score).nlargest(100).values[-1]], 1)# score[score >= pd.Series(score).nlargest(100).values[-1]]\n",
    "        top_100_doc_id = joined_df['doc_id'][score >= pd.Series(score).nlargest(100).values[-1]].values\n",
    "        score_dicts = [{doc:score} for (doc, score) in zip(top_100_doc_id, top_100_scores)]\n",
    "        predict_on_query.append(list(top_100_doc_id))\n",
    "        predicted_scores.append(list(top_100_scores))\n",
    "    return predict_on_query, predicted_scores\n",
    "\n",
    "joined_df['predict_100'], joined_df['predict_100_score'] = predicting_100_top_doc_id(joined_df, bm25)\n",
    "joined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da01e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_eval import Qrels, Run, evaluate\n",
    "qrels = Qrels()\n",
    "qrels.add_multi(q_ids=[str(i) for i in list(joined_df['query_id'].values)], \n",
    "                doc_ids=[[i] for i in joined_df['doc_id']],\n",
    "                scores=[[1.0] for i in range(len(joined_df))])\n",
    "\n",
    "run = Run()\n",
    "run.add_multi(q_ids=[str(i) for i in list(joined_df['query_id'].values)], \n",
    "                doc_ids=[i for i in joined_df['predict_100']],\n",
    "                scores=[i for i in joined_df['predict_100_score']]) # [[1.0] * 100 for i in range(len(joined_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "119c0403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634357665450471"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, run, [\"mrr@100\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff833e",
   "metadata": {},
   "source": [
    "### 0.7628803417941733 on dev 2 epochs with 30k docs\n",
    "### 0.7613182061766149 on dev 1 epoch with 50k docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
